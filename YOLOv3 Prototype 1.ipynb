{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vid capture\n",
    "cap = cv2.VideoCapture('/Users/raffaelenardi/Documents/GITHUB/State of the Art Technology/proto_test1.MOV')\n",
    "whT = 320\n",
    "confThreshold = 0.5\n",
    "nms_Throshold = 0.3\n",
    "\n",
    "classesFile = 'coco.names'\n",
    "classNames = [] #could just manualy add. maybe faster?\n",
    "\n",
    "with open(classesFile, 'rt') as f:\n",
    "    classNames = f.read().rstrip('\\n').split('\\n')\n",
    "\n",
    "# print(classNames)\n",
    "# print(len(classNames))\n",
    "\n",
    "#Architecture and wights\n",
    "modelConfiguration = 'yolov3.cfg'\n",
    "modelWeights = 'yolov3.weights'\n",
    "\n",
    "#Setup of OpenCV as Output\n",
    "net = cv2.dnn.readNetFromDarknet(modelConfiguration, modelWeights)\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
    "\n",
    "#Find OBJ function\n",
    "def findObjects(outputs,img):\n",
    "    hT, wT, cT = img.shape\n",
    "    bbox = []\n",
    "    classIds = []\n",
    "    confs = []\n",
    "    \n",
    "    for output in outputs:\n",
    "        for det in output:\n",
    "            scores = det[5:] # Removes first 5 elements\n",
    "            classId = np.argmax(scores) # Finds the index for max conf. score\n",
    "            confidence = scores[classId] # Saves actual value for the max conf. score\n",
    "            if confidence > confThreshold: #good detection\n",
    "                w,h = int(det[2]*wT), int(det[3]*hT) #extracts the w/h values from detection\n",
    "                x, y = int((det[0]*wT)-w/2), int((det[1]*hT)-h/2) #values in det are cx and cy so they need manipulation\n",
    "                bbox.append([x,y,w,h]) #appending bboxs\n",
    "                classIds.append(classId) #append classids\n",
    "                confs.append(float(confidence)) #append conf. values\n",
    "\n",
    "    indicies = cv2.dnn.NMSBoxes(bbox,confs,confThreshold,nms_Throshold) #This helps address multiple detections and keeps the best one only\n",
    "\n",
    "    for i in indicies:\n",
    "        i = i[0]\n",
    "        box = bbox[i]\n",
    "        x,y,w,h = box[0], box[1], box[2], box[3]\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h), (255,0,0), 2) #creates bbox in img\n",
    "        cv2.putText(img,f'{classNames[classIds[i]].upper()} {int(confs[i]*100)}%',\n",
    "                   (x,y-10),cv2.FONT_HERSHEY_SIMPLEX,0.6,(255,0,0),2)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-7de862b70496>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    success, img = cap.read()\n",
    "    \n",
    "    #Blob is format network understands\n",
    "    blob = cv2.dnn.blobFromImage(img,1/255,(whT,whT),[0,0,0],1,crop=False)\n",
    "    net.setInput(blob)\n",
    "    \n",
    "    # extracts layer names\n",
    "    layerNames = net.getLayerNames()\n",
    "    outputNames = [layerNames[i[0]-1] for i in net.getUnconnectedOutLayers()]\n",
    "    \n",
    "    outputs = net.forward(outputNames)\n",
    "    \n",
    "    findObjects(outputs,img) #calls function that adds boxes and conf. values\n",
    "    \n",
    "    cv2.imshow('img', img)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
